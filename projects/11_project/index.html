<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Recommender Systems | Jakhongir Saydaliev </title> <meta name="author" content="Jakhongir Saydaliev"> <meta name="description" content="Compares collaborative filtering, matrix factorization, and neural networks"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/profile.png?9eec2f327f2e2cf3da5d0adcec110cea"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jakhongir0103.github.io/projects/11_project/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jakhongir</span> Saydaliev </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/_pages/cv/">cv </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Recommender Systems</h1> <p class="post-description">Compares collaborative filtering, matrix factorization, and neural networks</p> </header> <article> <div class="links" style="margin-bottom: 2rem;"> <a href="https://github.com/Jakhongir0103/dis_projects/blob/main/pdfs/Project_2_Recommender_Systems.pdf" class="btn btn-primary btn-sm" role="button" target="_blank" style="background-color: white !important; border: 1px solid black !important; color: black !important; padding: 8px 16px; border-radius: 4px; text-decoration: none; display: inline-block; margin-right: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);" rel="external nofollow noopener"> <i class="fas fa-file-pdf"></i> Technical Report </a> </div> <p>With millions of books available online, effective recommendation systems are crucial for helping users discover titles they’ll love. In this project, we implemented and compared 4 different approaches to predicting user book ratings, pitting traditional machine learning against modern deep learning methods.</p> <h2 id="methods-4-approaches-to-recommendations">Methods: 4 Approaches to Recommendations</h2> <p><strong>Collaborative Filtering</strong> is the classic approach that recommends items based on similar users’ preferences. We tested both user-based filtering (finding similar users) and item-based filtering (finding similar books), combining the two for better performance. The main limitation? It struggles when users or items lack similar peers.</p> <p><strong>Matrix Factorization with ALS</strong> decomposes the user-book rating matrix into latent factors representing hidden patterns. Unlike collaborative filtering, this method excels at capturing the underlying structure in sparse data. We used Alternating Least Squares (ALS) to optimize the factorization, tuning the latent factor dimension to k=256.</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/dis2_mf_buomso-480.webp 480w,/assets/img/projects/dis2_mf_buomso-800.webp 800w,/assets/img/projects/dis2_mf_buomso-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/dis2_mf_buomso.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Matrix factorization decomposition of the rating matrix" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Matrix factorization decomposition of the rating matrix. </div> <p><strong>Joint-Embeddings</strong> Neural Network adds non-linearity to matrix factorization by training embeddings through a multi-layer perceptron. This approach learns user and item representations jointly, potentially capturing more complex relationships than linear methods.</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/dis2_mf_nn_arch-480.webp 480w,/assets/img/projects/dis2_mf_nn_arch-800.webp 800w,/assets/img/projects/dis2_mf_nn_arch-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/dis2_mf_nn_arch.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Joint-embeddings neural network architecture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Joint-embeddings neural network architecture. </div> <p><strong>SLIM (Sparse Linear Methods)</strong> combines the speed of collaborative filtering with matrix factorization’s effectiveness by learning a sparse aggregation matrix. Its key strength is computational efficiency—we trained it in under 4 minutes using parallel processing.</p> <h2 id="results-matrix-factorization-dominates">Results: Matrix Factorization Dominates</h2> <p>Here’s where things get interesting. Our test set results tell a clear story:</p> <table data-toggle="table" class="table table-bordered table-hover text-center align-middle"> <thead class="table-light"> <tr> <th>Method</th> <th>RMSE</th> </tr> </thead> <tbody> <tr> <td><strong>Matrix Factorization (ALS)</strong></td> <td><strong>0.812</strong></td> </tr> <tr> <td>Collaborative Filtering (Aggregated)</td> <td>0.889</td> </tr> <tr> <td>SLIM (Aggregated)</td> <td>1.467</td> </tr> <tr> <td>Joint-Embeddings Neural Network</td> <td>1.453</td> </tr> </tbody> </table> <p><strong>Matrix Factorization (ALS) achieved the best performance with an RMSE of 0.812</strong>, significantly outperforming the other methods. Collaborative filtering came second at 0.889, while SLIM and the neural network lagged at 1.467 and 1.453 respectively.</p> <p>The superiority of matrix factorization makes sense—ALS directly optimizes for RMSE, matching our evaluation metric perfectly. However, the neural network’s dramatic performance drop from development set (0.843) to test set (1.453) was surprising and suggests potential overfitting issues worth investigating.</p> <p>Collaborative filtering’s weaker performance highlights its core limitation: it can only leverage rating patterns, missing richer contextual information. Interestingly, cosine similarity outperformed Pearson correlation, and aggregating both user-based and item-based predictions improved results consistently.</p> <h2 id="why-this-matters">Why This Matters</h2> <p>Our findings confirm what the Netflix Prize demonstrated years ago: <strong>latent factor models beat neighborhood-based approaches</strong> for recommendation tasks. Matrix factorization’s efficiency and accuracy make it the practical choice for production systems.</p> <p>However, the study reveals room for improvement. The dataset contained only user-book rating pairs with no additional context. Enriching this with metadata like author, genre, or publication year could unlock more sophisticated patterns and help hybrid approaches shine.</p> <h2 id="takeaway">Takeaway</h2> <p><strong>Matrix factorization</strong>, a relatively straightforward method, outperformed more sophisticated neural network approaches – a useful reminder that the best model isn’t always the most elaborate one.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jakhongir Saydaliev. Last updated: October 28, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?880f023ae5a3457786af14022ff676f0"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>