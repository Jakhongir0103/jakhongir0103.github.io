<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Document Retrieval | Jakhongir Saydaliev </title> <meta name="author" content="Jakhongir Saydaliev"> <meta name="description" content="Built an efficient IR system across 7 languages with computational limits"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/profile.png?9eec2f327f2e2cf3da5d0adcec110cea"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jakhongir0103.github.io/projects/document_retrieval/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jakhongir</span> Saydaliev </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Document Retrieval</h1> <p class="post-description">Built an efficient IR system across 7 languages with computational limits</p> </header> <article> <div class="links" style="margin-bottom: 2rem;"> <a href="https://github.com/Jakhongir0103/dis_projects/blob/main/pdfs/Project_1_Document_Retrieval.pdf" class="btn btn-primary btn-sm" role="button" target="_blank" style="background-color: white !important; border: 1px solid black !important; color: black !important; padding: 8px 16px; border-radius: 4px; text-decoration: none; display: inline-block; margin-right: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);" rel="external nofollow noopener"> <i class="fas fa-file-pdf"></i> Technical Report </a> </div> <p>When you need to search through 200,000+ documents across multiple languages-fast-the usual tricks might not work. Pre-trained language models deliver impressive results, but they’re computationally expensive. Our task: build a multilingual information retrieval system that’s both effective and resource-efficient.</p> <p>The setup was straightforward: retrieve the single most relevant document for each query from a corpus spanning 7 languages (Arabic, German, English, Spanish, French, Italian, and Korean). But here’s the catch – inference had to complete within 10 minutes, and we were limited to a Kaggle notebook’s resources.</p> <h2 id="our-approach">Our Approach</h2> <p>We tested three categories of methods, ranging from classical to modern:</p> <p><strong>TF-IDF</strong></p> <p>We started with <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="external nofollow noopener" target="_blank">TF-IDF</a>, a semantic method that weighs terms by their frequency and uniqueness. The baseline scored 0.52 on our test metric (Recall@10), but we improved it by boosting high-IDF terms—since rare terms often indicate query-specific documents. Using a scalar multiplier on the top 2 IDF terms increased performance to <strong>0.5871</strong>, a 10% boost.</p> <p><strong>BM25: The Winner</strong></p> <p><a href="https://en.wikipedia.org/wiki/Okapi_BM25" rel="external nofollow noopener" target="_blank">BM25</a> refined the TF-IDF approach by accounting for document length and term saturation effects. It’s a simple formula, but it works remarkably well:</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/dis1_IR_pipeline-480.webp 480w,/assets/img/projects/dis1_IR_pipeline-800.webp 800w,/assets/img/projects/dis1_IR_pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/dis1_IR_pipeline.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="IR System Pipeline" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> IR System Pipeline. </div> <p>The results were interesting: BM25 achieved <strong>0.7714</strong> on the dev set and <strong>0.7562</strong> on the final test submission. No complex models needed.</p> <p><strong>Text Embeddings</strong></p> <p>We tested <a href="https://huggingface.co/intfloat/multilingual-e5-small" rel="external nofollow noopener" target="_blank">multilingual-e5-small</a>, a compact embedding model with under 250M parameters. We tried two chunking strategies (20-word and 200-word sequences) to handle the attention mechanism’s length limitations. The results were disappointing: e5 with 200-word chunks scored only 0.5414, and shorter chunks performed even worse at 0.3028. Longer chunks provided better context but created language imbalances.</p> <p><strong>Reranking: The Diminishing Returns</strong></p> <p>We fine-tuned <a href="https://huggingface.co/distilbert/distilbert-base-uncased" rel="external nofollow noopener" target="_blank">DistilBERT</a> as a reranker to refine retrieved results. Unfortunately, adding reranking degraded performance for most models—likely due to the small model size. It slightly helped text embedding methods but hurt the strong keyword-based methods. For our final submission, we stuck with pure BM25.</p> <h2 id="the-results">The Results</h2> <p>Below are the results of fine-tuned models:</p> <div class="row justify-content-sm-center"> <div class="col-sm-10 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/dis1_rerankers_perf-size-480.webp 480w,/assets/img/projects/dis1_rerankers_perf-size-800.webp 800w,/assets/img/projects/dis1_rerankers_perf-size-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/dis1_rerankers_perf-size.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reranker performance based on different models" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fine-tuned models' performances. </div> <p>Here is the comparison of all methods for each language.</p> <table data-toggle="table" class="table table-bordered table-hover text-center align-middle"> <thead class="table-light"> <tr> <th></th> <th>ar</th> <th>de</th> <th>en</th> <th>es</th> <th>fr</th> <th>it</th> <th>ko</th> </tr> </thead> <tbody> <tr> <td><strong>TF-IDF (Baseline)</strong></td> <td>0.460</td> <td>0.450</td> <td>0.495</td> <td>0.760</td> <td>0.715</td> <td>0.595</td> <td>0.465</td> </tr> <tr> <td><strong>TF-IDF (Optimal)</strong></td> <td>0.585</td> <td>0.560</td> <td>0.450</td> <td>0.775</td> <td>0.790</td> <td>0.610</td> <td>0.605</td> </tr> <tr> <td><strong>e5_sl200</strong></td> <td>0.420</td> <td>0.425</td> <td>0.520</td> <td>0.685</td> <td>0.670</td> <td>0.555</td> <td>0.515</td> </tr> <tr> <td><strong>BM25</strong></td> <td><strong>0.735</strong></td> <td><strong>0.665</strong></td> <td><strong>0.745</strong></td> <td><strong>0.910</strong></td> <td><strong>0.910</strong></td> <td><strong>0.770</strong></td> <td><strong>0.625</strong></td> </tr> <tr> <td><strong>TF-IDF + Rerank (Baseline)</strong></td> <td>0.460</td> <td>0.470</td> <td>0.490</td> <td>0.755</td> <td>0.725</td> <td>0.610</td> <td>0.460</td> </tr> <tr> <td><strong>TF-IDF + Rerank (Optimal)</strong></td> <td>0.580</td> <td>0.555</td> <td>0.450</td> <td>0.775</td> <td>0.790</td> <td>0.605</td> <td>0.600</td> </tr> <tr> <td><strong>e5_sl200 + Rerank</strong></td> <td>0.440</td> <td>0.435</td> <td>0.525</td> <td>0.675</td> <td>0.685</td> <td>0.565</td> <td>0.520</td> </tr> <tr> <td><u><strong>BM25 + Rerank</strong></u></td> <td>0.725</td> <td>0.660</td> <td>0.735</td> <td>0.895</td> <td>0.895</td> <td>0.765</td> <td>0.620</td> </tr> </tbody> </table> <div class="caption"> Recall@10 per language for different retrieval models and configurations. </div> <p>BM25 dominated across all 7 languages, with particularly strong performance in Spanish (0.91) and French (0.91). Even on less-resourced languages like Korean, it achieved 0.625.</p> <h2 id="takeaways">Takeaways</h2> <p>In constrained environments, classical information retrieval methods like BM25 outperform small embedding models because they’re efficient, interpretable, and surprisingly effective at keyword matching. Text embeddings excel at semantic understanding, but they’re overkill when you don’t have the computational resources to properly leverage them.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jakhongir Saydaliev. Last updated: November 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?880f023ae5a3457786af14022ff676f0"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>